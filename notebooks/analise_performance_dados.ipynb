{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise de Performance e Qualidade dos Dados SINAN\n",
    "\n",
    "Este notebook analisa:\n",
    "\n",
    "- Tempo de carregamento dos dados\n",
    "- Uso de mem√≥ria\n",
    "- Colunas dispon√≠veis e suas caracter√≠sticas\n",
    "- Gargalos de performance\n",
    "- Qualidade dos dados (valores nulos, tipos, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Adicionar o diret√≥rio raiz ao path para importar m√≥dulos\n",
    "sys.path.append('.')\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An√°lise de Mem√≥ria e Performance Inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Retorna o uso de mem√≥ria atual em MB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "def format_bytes(bytes_size):\n",
    "    \"\"\"Formata bytes para formato leg√≠vel\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if bytes_size < 1024.0:\n",
    "            return f\"{bytes_size:.2f} {unit}\"\n",
    "        bytes_size /= 1024.0\n",
    "    return f\"{bytes_size:.2f} PB\"\n",
    "\n",
    "memoria_inicial = get_memory_usage()\n",
    "print(f\"Mem√≥ria inicial: {memoria_inicial:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar Dados e Medir Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar arquivos Parquet\n",
    "parquet_dir = Path('data/raw/VIOLBR-PARQUET')\n",
    "arquivos_parquet = list(parquet_dir.glob('*.parquet'))\n",
    "\n",
    "print(f\"Arquivos Parquet encontrados: {len(arquivos_parquet)}\")\n",
    "for arquivo in arquivos_parquet:\n",
    "    tamanho = arquivo.stat().st_size\n",
    "    print(f\"  - {arquivo.name}: {format_bytes(tamanho)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar primeiro arquivo e medir tempo\n",
    "if arquivos_parquet:\n",
    "    arquivo_teste = arquivos_parquet[0]\n",
    "    \n",
    "    print(f\"\\nCarregando: {arquivo_teste.name}\")\n",
    "    \n",
    "    inicio = time.time()\n",
    "    mem_antes = get_memory_usage()\n",
    "    \n",
    "    df = pd.read_parquet(arquivo_teste)\n",
    "    \n",
    "    fim = time.time()\n",
    "    mem_depois = get_memory_usage()\n",
    "    \n",
    "    tempo_carregamento = fim - inicio\n",
    "    memoria_usada = mem_depois - mem_antes\n",
    "    \n",
    "    print(f\"\\n=== RESULTADOS DO CARREGAMENTO ===\")\n",
    "    print(f\"Tempo de carregamento: {tempo_carregamento:.2f} segundos\")\n",
    "    print(f\"Mem√≥ria usada: {memoria_usada:.2f} MB\")\n",
    "    print(f\"Mem√≥ria total ap√≥s carregamento: {mem_depois:.2f} MB\")\n",
    "    print(f\"\\nShape do DataFrame: {df.shape}\")\n",
    "    print(f\"Total de registros: {len(df):,}\")\n",
    "    print(f\"Total de colunas: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lise Detalhada das Colunas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"=== INFORMA√á√ïES GERAIS DO DATAFRAME ===\")\n",
    "    print(f\"\\nColunas ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:3d}. {col}\")\n",
    "    \n",
    "    print(f\"\\n\\nTipos de dados:\")\n",
    "    tipos = df.dtypes.value_counts()\n",
    "    for tipo, count in tipos.items():\n",
    "        print(f\"  {tipo}: {count} colunas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada de cada coluna\n",
    "if 'df' in locals():\n",
    "    print(\"\\n=== AN√ÅLISE DETALHADA POR COLUNA ===\\n\")\n",
    "    \n",
    "    analise_colunas = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        inicio_col = time.time()\n",
    "        \n",
    "        # Informa√ß√µes b√°sicas\n",
    "        tipo = str(df[col].dtype)\n",
    "        total = len(df)\n",
    "        nulos = df[col].isna().sum()\n",
    "        percentual_nulos = (nulos / total * 100) if total > 0 else 0\n",
    "        \n",
    "        # Mem√≥ria usada pela coluna\n",
    "        memoria_col = df[col].memory_usage(deep=True) / 1024 / 1024  # MB\n",
    "        \n",
    "        # Valores √∫nicos (apenas para colunas com poucos valores √∫nicos)\n",
    "        valores_unicos = df[col].nunique()\n",
    "        \n",
    "        tempo_analise = time.time() - inicio_col\n",
    "        \n",
    "        analise_colunas.append({\n",
    "            'Coluna': col,\n",
    "            'Tipo': tipo,\n",
    "            'Total': total,\n",
    "            'Nulos': nulos,\n",
    "            '% Nulos': f\"{percentual_nulos:.2f}%\",\n",
    "            'Valores √önicos': valores_unicos,\n",
    "            'Mem√≥ria (MB)': f\"{memoria_col:.2f}\",\n",
    "            'Tempo An√°lise (s)': f\"{tempo_analise:.4f}\"\n",
    "        })\n",
    "    \n",
    "    df_analise = pd.DataFrame(analise_colunas)\n",
    "    \n",
    "    # Ordenar por mem√≥ria (maiores primeiro)\n",
    "    df_analise['Memoria_Num'] = df_analise['Mem√≥ria (MB)'].astype(float)\n",
    "    df_analise = df_analise.sort_values('Memoria_Num', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 colunas que mais consomem mem√≥ria:\")\n",
    "    display(df_analise[['Coluna', 'Tipo', 'Mem√≥ria (MB)', '% Nulos', 'Valores √önicos']].head(20))\n",
    "    \n",
    "    print(\"\\n\\nColunas com mais valores nulos:\")\n",
    "    df_analise['Nulos_Num'] = df_analise['Nulos'].astype(int)\n",
    "    display(df_analise[['Coluna', 'Nulos', '% Nulos']].sort_values('Nulos_Num', ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identificar Gargalos de Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"=== TESTES DE PERFORMANCE ===\\n\")\n",
    "    \n",
    "    # Teste 1: Filtro simples\n",
    "    print(\"1. Testando filtro simples (SEXO == 'F'):\")\n",
    "    inicio = time.time()\n",
    "    if 'SEXO' in df.columns:\n",
    "        resultado = df[df['SEXO'] == 'F']\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"   Tempo: {tempo:.4f}s | Registros encontrados: {len(resultado):,}\")\n",
    "    else:\n",
    "        print(\"   Coluna SEXO n√£o encontrada\")\n",
    "    \n",
    "    # Teste 2: Agrupamento\n",
    "    print(\"\\n2. Testando agrupamento (por UF):\")\n",
    "    inicio = time.time()\n",
    "    if 'UF_NOTIFIC' in df.columns:\n",
    "        resultado = df.groupby('UF_NOTIFIC').size()\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"   Tempo: {tempo:.4f}s | Grupos: {len(resultado)}\")\n",
    "    else:\n",
    "        print(\"   Coluna UF_NOTIFIC n√£o encontrada\")\n",
    "    \n",
    "    # Teste 3: Aplicar fun√ß√£o\n",
    "    print(\"\\n3. Testando apply (criar faixa et√°ria):\")\n",
    "    inicio = time.time()\n",
    "    if 'NU_IDADE_N' in df.columns:\n",
    "        def get_age_group(idade):\n",
    "            if pd.isna(idade):\n",
    "                return 'N√£o informado'\n",
    "            idade_int = int(idade) if isinstance(idade, (int, float)) else 0\n",
    "            if idade_int < 2:\n",
    "                return '0-1 anos'\n",
    "            elif idade_int < 6:\n",
    "                return '2-5 anos'\n",
    "            elif idade_int < 10:\n",
    "                return '6-9 anos'\n",
    "            elif idade_int < 14:\n",
    "                return '10-13 anos'\n",
    "            elif idade_int < 18:\n",
    "                return '14-17 anos'\n",
    "            else:\n",
    "                return '18+ anos'\n",
    "        \n",
    "        resultado = df['NU_IDADE_N'].apply(get_age_group)\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"   Tempo: {tempo:.4f}s | Valores √∫nicos: {resultado.nunique()}\")\n",
    "    else:\n",
    "        print(\"   Coluna NU_IDADE_N n√£o encontrada\")\n",
    "    \n",
    "    # Teste 4: Convers√£o de data\n",
    "    print(\"\\n4. Testando convers√£o de data (DT_NOTIFIC):\")\n",
    "    inicio = time.time()\n",
    "    if 'DT_NOTIFIC' in df.columns:\n",
    "        try:\n",
    "            resultado = pd.to_datetime(df['DT_NOTIFIC'], format='%Y%m%d', errors='coerce')\n",
    "            tempo = time.time() - inicio\n",
    "            print(f\"   Tempo: {tempo:.4f}s | Datas v√°lidas: {resultado.notna().sum():,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Erro: {e}\")\n",
    "    else:\n",
    "        print(\"   Coluna DT_NOTIFIC n√£o encontrada\")\n",
    "    \n",
    "    # Teste 5: M√∫ltiplos filtros\n",
    "    print(\"\\n5. Testando m√∫ltiplos filtros (UF + SEXO + Idade):\")\n",
    "    inicio = time.time()\n",
    "    filtros = []\n",
    "    if 'UF_NOTIFIC' in df.columns:\n",
    "        filtros.append(df['UF_NOTIFIC'] == df['UF_NOTIFIC'].iloc[0] if len(df) > 0 else False)\n",
    "    if 'SEXO' in df.columns:\n",
    "        filtros.append(df['SEXO'] == 'F')\n",
    "    if 'NU_IDADE_N' in df.columns:\n",
    "        filtros.append(df['NU_IDADE_N'] < 18)\n",
    "    \n",
    "    if filtros:\n",
    "        mask = pd.concat(filtros, axis=1).all(axis=1) if len(filtros) > 1 else filtros[0]\n",
    "        resultado = df[mask]\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"   Tempo: {tempo:.4f}s | Registros encontrados: {len(resultado):,}\")\n",
    "    else:\n",
    "        print(\"   Colunas necess√°rias n√£o encontradas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"=== AN√ÅLISE DE MEM√ìRIA ===\\n\")\n",
    "    \n",
    "    memoria_atual = get_memory_usage()\n",
    "    memoria_df = df.memory_usage(deep=True).sum() / 1024 / 1024  # MB\n",
    "    \n",
    "    print(f\"Mem√≥ria total do processo: {memoria_atual:.2f} MB\")\n",
    "    print(f\"Mem√≥ria usada pelo DataFrame: {memoria_df:.2f} MB\")\n",
    "    print(f\"Mem√≥ria adicional (overhead): {memoria_atual - memoria_df:.2f} MB\")\n",
    "    \n",
    "    # An√°lise por tipo de dado\n",
    "    print(\"\\nMem√≥ria por tipo de dado:\")\n",
    "    memoria_por_tipo = df.memory_usage(deep=True).groupby(df.dtypes).sum() / 1024 / 1024\n",
    "    for tipo, memoria in memoria_por_tipo.items():\n",
    "        print(f\"  {tipo}: {memoria:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recomenda√ß√µes de Otimiza√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and 'df_analise' in locals():\n",
    "    print(\"=== RECOMENDA√á√ïES DE OTIMIZA√á√ÉO ===\\n\")\n",
    "    \n",
    "    recomendacoes = []\n",
    "    \n",
    "    # Verificar colunas com muitos nulos\n",
    "    colunas_muitos_nulos = df_analise[df_analise['Nulos_Num'] > len(df) * 0.9]\n",
    "    if len(colunas_muitos_nulos) > 0:\n",
    "        recomendacoes.append({\n",
    "            'Tipo': 'Qualidade de Dados',\n",
    "            'Problema': f'{len(colunas_muitos_nulos)} colunas com >90% de valores nulos',\n",
    "            'Recomenda√ß√£o': 'Considerar remover essas colunas ou usar sparse arrays',\n",
    "            'Colunas': ', '.join(colunas_muitos_nulos['Coluna'].head(5).tolist())\n",
    "        })\n",
    "    \n",
    "    # Verificar colunas object que poderiam ser category\n",
    "    colunas_object = df.select_dtypes(include=['object']).columns\n",
    "    colunas_candidatas_category = []\n",
    "    for col in colunas_object:\n",
    "        if df[col].nunique() < len(df) * 0.1:  # Menos de 10% de valores √∫nicos\n",
    "            colunas_candidatas_category.append(col)\n",
    "    \n",
    "    if colunas_candidatas_category:\n",
    "        recomendacoes.append({\n",
    "            'Tipo': 'Otimiza√ß√£o de Mem√≥ria',\n",
    "            'Problema': f'{len(colunas_candidatas_category)} colunas object com poucos valores √∫nicos',\n",
    "            'Recomenda√ß√£o': 'Converter para category para economizar mem√≥ria',\n",
    "            'Colunas': ', '.join(colunas_candidatas_category[:5])\n",
    "        })\n",
    "    \n",
    "    # Verificar colunas num√©ricas que poderiam ser tipos menores\n",
    "    colunas_int64 = df.select_dtypes(include=['int64']).columns\n",
    "    colunas_candidatas_int32 = []\n",
    "    for col in colunas_int64:\n",
    "        if df[col].min() >= np.iinfo(np.int32).min and df[col].max() <= np.iinfo(np.int32).max:\n",
    "            colunas_candidatas_int32.append(col)\n",
    "    \n",
    "    if colunas_candidatas_int32:\n",
    "        recomendacoes.append({\n",
    "            'Tipo': 'Otimiza√ß√£o de Mem√≥ria',\n",
    "            'Problema': f'{len(colunas_candidatas_int32)} colunas int64 que cabem em int32',\n",
    "            'Recomenda√ß√£o': 'Converter para int32 para economizar 50% de mem√≥ria',\n",
    "            'Colunas': ', '.join(colunas_candidatas_int32[:5])\n",
    "        })\n",
    "    \n",
    "    # Verificar se DuckDB seria √∫til\n",
    "    if len(df) > 1_000_000:\n",
    "        recomendacoes.append({\n",
    "            'Tipo': 'Performance',\n",
    "            'Problema': f'Dataset grande ({len(df):,} registros)',\n",
    "            'Recomenda√ß√£o': 'Considerar usar DuckDB para queries mais r√°pidas',\n",
    "            'Colunas': 'N/A'\n",
    "        })\n",
    "    \n",
    "    if recomendacoes:\n",
    "        df_recomendacoes = pd.DataFrame(recomendacoes)\n",
    "        display(df_recomendacoes)\n",
    "    else:\n",
    "        print(\"Nenhuma recomenda√ß√£o espec√≠fica. Os dados parecem estar bem otimizados!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compara√ß√£o: Pandas vs DuckDB (se dispon√≠vel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import duckdb\n",
    "    \n",
    "    if 'df' in locals():\n",
    "        print(\"=== COMPARA√á√ÉO PANDAS vs DUCKDB ===\\n\")\n",
    "        \n",
    "        # Teste 1: Filtro simples\n",
    "        print(\"1. Filtro simples (SEXO == 'F'):\")\n",
    "        \n",
    "        # Pandas\n",
    "        inicio = time.time()\n",
    "        if 'SEXO' in df.columns:\n",
    "            resultado_pandas = df[df['SEXO'] == 'F']\n",
    "            tempo_pandas = time.time() - inicio\n",
    "            print(f\"   Pandas: {tempo_pandas:.4f}s\")\n",
    "        \n",
    "        # DuckDB\n",
    "        inicio = time.time()\n",
    "        if 'SEXO' in df.columns:\n",
    "            resultado_duckdb = duckdb.sql(\"SELECT * FROM df WHERE SEXO = 'F'\").df()\n",
    "            tempo_duckdb = time.time() - inicio\n",
    "            print(f\"   DuckDB: {tempo_duckdb:.4f}s\")\n",
    "            print(f\"   Ganho: {tempo_pandas/tempo_duckdb:.2f}x mais r√°pido\" if tempo_duckdb > 0 else \"   N/A\")\n",
    "        \n",
    "        # Teste 2: Agrupamento\n",
    "        print(\"\\n2. Agrupamento (por UF):\")\n",
    "        \n",
    "        # Pandas\n",
    "        inicio = time.time()\n",
    "        if 'UF_NOTIFIC' in df.columns:\n",
    "            resultado_pandas = df.groupby('UF_NOTIFIC').size()\n",
    "            tempo_pandas = time.time() - inicio\n",
    "            print(f\"   Pandas: {tempo_pandas:.4f}s\")\n",
    "        \n",
    "        # DuckDB\n",
    "        inicio = time.time()\n",
    "        if 'UF_NOTIFIC' in df.columns:\n",
    "            resultado_duckdb = duckdb.sql(\"SELECT UF_NOTIFIC, COUNT(*) as count FROM df GROUP BY UF_NOTIFIC\").df()\n",
    "            tempo_duckdb = time.time() - inicio\n",
    "            print(f\"   DuckDB: {tempo_duckdb:.4f}s\")\n",
    "            print(f\"   Ganho: {tempo_pandas/tempo_duckdb:.2f}x mais r√°pido\" if tempo_duckdb > 0 else \"   N/A\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"DuckDB n√£o est√° instalado. Para comparar performance, instale com: pip install duckdb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"=== RESUMO EXECUTIVO ===\\n\")\n",
    "    \n",
    "    print(f\"üìä DADOS:\")\n",
    "    print(f\"   - Total de registros: {len(df):,}\")\n",
    "    print(f\"   - Total de colunas: {len(df.columns)}\")\n",
    "    print(f\"   - Tamanho em mem√≥ria: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n‚ö° PERFORMANCE:\")\n",
    "    if 'tempo_carregamento' in locals():\n",
    "        print(f\"   - Tempo de carregamento: {tempo_carregamento:.2f}s\")\n",
    "    if 'memoria_usada' in locals():\n",
    "        print(f\"   - Mem√≥ria usada: {memoria_usada:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüìà QUALIDADE:\")\n",
    "    total_nulos = df.isna().sum().sum()\n",
    "    total_celulas = len(df) * len(df.columns)\n",
    "    percentual_nulos = (total_nulos / total_celulas * 100) if total_celulas > 0 else 0\n",
    "    print(f\"   - Total de valores nulos: {total_nulos:,} ({percentual_nulos:.2f}%)\")\n",
    "    \n",
    "    colunas_completas = (df.isna().sum() == 0).sum()\n",
    "    print(f\"   - Colunas sem valores nulos: {colunas_completas}/{len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nüí° PRINCIPAIS GARGALOS IDENTIFICADOS:\")\n",
    "    if 'df_analise' in locals():\n",
    "        top_gargalos = df_analise.nlargest(5, 'Memoria_Num')\n",
    "        for idx, row in top_gargalos.iterrows():\n",
    "            print(f\"   - {row['Coluna']}: {row['Mem√≥ria (MB)']} MB ({row['% Nulos']} nulos)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ PR√ìXIMOS PASSOS:\")\n",
    "    print(f\"   1. Revisar recomenda√ß√µes de otimiza√ß√£o acima\")\n",
    "    print(f\"   2. Considerar usar DuckDB para queries complexas\")\n",
    "    print(f\"   3. Avaliar remover colunas com muitos valores nulos\")\n",
    "    print(f\"   4. Converter colunas object para category quando apropriado\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
